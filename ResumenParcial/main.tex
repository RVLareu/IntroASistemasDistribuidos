\documentclass[titlepage,a4paper]{article}

\usepackage{a4wide}
\usepackage[colorlinks=true,linkcolor=black,urlcolor=blue,bookmarksopen=true]{hyperref}
\usepackage{bookmark}
\usepackage{fancyhdr}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\pagestyle{fancy} % Encabezado y pie de página
\fancyhf{}
\fancyhead[L]{Ejercicios de Parcial}
\fancyhead[R]{Introducción a Sistemas Distribuidos - FIUBA}
\renewcommand{\headrulewidth}{0.4pt}
\fancyfoot[C]{\thepage}
\renewcommand{\footrulewidth}{0.4pt}



% code listing settings
\usepackage{listings}
\renewcommand{\lstlistingname}{Código \textnumero{}}
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    aboveskip={1.0\baselineskip},
    belowskip={1.0\baselineskip},
    columns=fixed,
    extendedchars=true,
    breaklines=true,
    tabsize=4,
    prebreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
    frame=lines,
    showtabs=false,
    showspaces=false,
    showstringspaces=false,
    keywordstyle=\color[rgb]{0.627,0.126,0.941},
    commentstyle=\color[rgb]{0.133,0.545,0.133},
    stringstyle=\color[rgb]{01,0,0},
    numbers=left,
    numberstyle=\small,
    stepnumber=1,
    numbersep=10pt,
    captionpos=t,
    escapeinside={\%*}{*)}
}


\begin{document}
\begin{titlepage} % Carátula
	\hfill\includegraphics[width=6cm]{imagenes/logofiuba.jpg}
    \centering
    \vfill
    \Huge \textbf{Resumen parcial}
    \vskip2cm
    \Large [75.43]  Introducción Sistemas Distribuidos\\
    Curso Hamelin \\ 
    Primer cuatrimestre de 2022 
    \vfill
    \begin{tabular}{ | l | l | } % Datos del alumno
      \hline
      VAZQUEZ LAREU, Román & 100815 \\ \hline
      

  	\end{tabular}
    \vfill
    \vfill
\end{titlepage}

\tableofcontents % Índice general
\newpage

\section{Calcular RTT}\label{sec:CalcularRTT}

\textbf{Tiempo de inserción}: tiempo que tarda el paquete en ser insertado en el enlace

$$t_{ins} = \frac{L}{R}$$ 

\begin{itemize}
    \item $L$: largo del paquete
    \item $R$: velocidad de serialización
\end{itemize}


\textbf{Tiempo de propagación}: Tiempo que demora el paquete en propagarse por el enlace de un router al próximo

$$t_{prop} = \frac{d}{c}$$

\begin{itemize}
    \item $d$: distancia entre extremos del enlace
    \item $c$: velocidad del medio
        \subitem Aire: $c = 3x10^8 \frac{m}{s}$
        \subitem Fibra, cobre,etc: $\frac{2}{3} c$ 
\end{itemize}


\textbf{Qué tiempo es más influyente?}
\begin{itemize}
    \item Distancias largas: $ t_{ins} <  t_{prop} $
    \item Distancias cortas: $ t_{ins} > t_{prop}$
\end{itemize}





\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/ejercicioRtt.png}
\end{figure}


RTT o Round-Trip-Time es el tiempo que tarda un paquete de datos enviado desde un emisor en volver
al mismo emisor habiendo pasado por el receptor de destino.

Al tener las velocidades de propagación en $\frac{Km}{s}$, se pasan las distancias a $Km$

$$D_{L1} = 100 m = 0.1 \; Km$$
$$D_{L2} = 10 \; Km$$
$$D_{L3} = 4 \; Km$$
$$D_{L4} = 100 m = 0.1 \; Km$$

Se pasa el ancho de banda a $bits/seg$

$$t_{ins1} = 10 Mbps = 10^7 \frac{bits}{seg}$$
$$t_{ins2} = 200 Mbps = 20\cdot 10^7 \frac{bits}{seg}$$
$$t_{ins3} = 200 Mbps = 20\cdot 10^7 \frac{bits}{seg}$$
$$t_{ins4} = 10 Mbps = 10^7 \frac{bits}{seg}$$

Largo del paquete a $bits$

$$1000 \; bytes = 8000 \; bits$$

\textbf{Análisis tiempo de inserción}: \\


\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/tiempoInsercion.png}
\end{figure}



Ida:

$$ t_{insIDA} = t_{insL1} + t_{insL2} + t_{insL3} +t_{insL4} $$ 
$$\frac{8000 bits}{10^7 \frac{bits}{seg}}  + \frac{8000 bits}{20\cdot 10^7 \frac{bits}{seg}}  + \frac{8000 bits}{20\cdot 10^7 \frac{bits}{seg}} + \frac{8000 bits}{10^7 \frac{bits}{seg}} = 1.68 \cdot 10^-3 seg$$

Vuelta:

$$ t_{insVUELTA} = t_{insL4} + t_{insL3} + t_{insL2} +t_{insL1} $$ 
$$  \frac{8000 bits}{10^7 \frac{bits}{seg}}  + \frac{8000 bits}{20\cdot 10^7 \frac{bits}{seg}}  + \frac{8000 bits}{20\cdot 10^7 \frac{bits}{seg}} + \frac{8000 bits}{10^7 \frac{bits}{seg}} = 1.68 \cdot 10^{-3} seg $$

Total:

$$ t_{ins} = t_{insIDA} + t_{insVUELTA} =   1.68 \cdot 10^{-3} seg +  1.68 \cdot 10^{-3} seg =  3.36 \cdot 10^{-3} \; seg$$


\textbf{Análisis tiempo de propagación}: \\

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/tiempoPropagacion.png}
\end{figure}

Ida:

$$t_{propIDA} = t_{propL1} + t_{propL2}  + t_{propL3} + t_{propL4} $$ 
$$ \frac{0.1 \; Km}{1.7\cdot10^5\frac{Km}{seg}} + \frac{10 \; Km}{2\cdot10^5\frac{Km}{seg}} + \frac{4 \; Km}{2\cdot10^5\frac{Km}{seg}} + \frac{0.1 \; Km}{1.7\cdot10^5\frac{Km}{seg}} = 7.11765 \cdot 10^{-5} \; seg $$

Vuelta:

$$t_{propVUELTA} = t_{propL4} + t_{propL3} + t_{propL2} + t_{propL1} $$ 
$$ \frac{0.1 \; Km}{1.7\cdot10^5\frac{Km}{seg}} + \frac{10 \; Km}{2\cdot10^5\frac{Km}{seg}} + \frac{4 \; Km}{2\cdot10^5\frac{Km}{seg}} + \frac{0.1 \; Km}{1.7\cdot10^5\frac{Km}{seg}} = 7.11765 \cdot 10^{-5} \; seg  $$

Total:

$$t_{prop} = t_{propIDA} + t_{propVUELTA}  =  7.11765 \cdot 10^{-5} \; seg + 7.11765 \cdot 10^{-5} \; seg = 1.42353\cdot10^{-4} \; seg$$

\textbf{Resolución final}:

$$ t_{prop} + t_{ins} = 1.42353\cdot10^{-4} \; seg + 3.36 \cdot 10^{-3} \; seg = 3.50235 \cdot 10^{-3} \; seg$$

$$ RTT = 3.5 \; ms$$


\subsection{Otros}

\textbf{Tiempo de procesamiento}: es el tiempo que requiere el procesamiento del paquete en los routers. Implica leer el header y tomar la decisión de por cuál enlace enviarlo. Los órdenes de tiempo se encuentran entre los nano y microsegundos ($ns$, $\mu s$ )

\textbf{Tiempo de encolado}: es el tiempo que espera paquete en el router desde que arriba hasta que es finalmente transmitido. Depende de la tasa de desocupación del router, del tamaño de la cola. A mayor tráfico, mayor tiempo encolado. Este tiempo no es constante sino aleatorio, varía con el tráfico

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/tiempoEncolado.png}
\caption{Tiempo de Encolado}
\end{figure}

\begin{itemize}
    \item L: largo del paquete
    \item a: tasa de arribo promedio de paquete
    \item R: velocidad de serialización
\end{itemize}

Si $L \cdot a > R$, significa que están llegando más paquetes que los que el router puede procesar, se va llenando el buffer hasta estarlo por completo y comenzar a descartar paquetes. Si $L \cdot a = R$ la cola se llena, entonces la solución es la subutilización, es decir $L \cdot a < R$

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/tiemposRTT.png}
\caption{Tiempo de Encolado}
\end{figure}

\section{Agregación de prefijos}\label{sec:agrprefijos}

Permite reducir la cantidad de entradas en la tabla de ruteo. Puede realizarse cuando \textbf{las redes son contiguas} y cuando tienen \textbf{idéntico Next Hop o puerto de salida}. Se dice que dos redes son contiguas cuando tienen \textbf{prefijos de igual longitud} y \textbf{la máscara sólo difiere en el último bit}


\subsection{Caso Favorable}

\begin{center}
    \begin{tabular}{c|c}
        Máscara & Puerto de salida \\
        \hline
        \hline
         192.168.0.0/24 &  0\\
         \hline
         192.168.1.0/24 &  0
    \end{tabular}
\end{center}

El \textbf{/24} indica que deben tomarse los primeros 24 bits
Si pasamos a binario:

\begin{center}
    \begin{tabular}{c|c|c|c}
        0-7 bits & 8-14 bits & 15-23 bits & 24-31 bits \\
        \hline
        \hline
        192 & 168 & 0000000 \textbf{0} & 00000000 \\
        \hline
        192 & 168 & 0000000 \textbf{1} & 00000000 \\
    \end{tabular}
\end{center}

Difieren sólo en el último bit (el bit número 24) y el prefijo es de igual longitud, por lo que son contiguas. Además tienen el mismo puerto de salida. Se puede hacer agregación de prefijos

\begin{center}
    \begin{tabular}{c|c}
        Máscara & Puerto de salida \\
        \hline
        \hline
         192.168.0.\textbf{0/23} &  0\\
    \end{tabular}
\end{center}

Se disminuyó en uno la máscara y se las unificó en una sola red

\subsection{Caso Desfavorable por no ser contiguas - bit}

\begin{center}
    \begin{tabular}{c|c}
        Máscara & Puerto de salida \\
        \hline
        \hline
         192.168.1.0/24 &  0\\
         \hline
         192.168.2.0/24 &  0
    \end{tabular}
\end{center}

El \textbf{/24} indica que deben tomarse los primeros 24 bits
Si pasamos a binario:

\begin{center}
    \begin{tabular}{c|c|c|c}
        0-7 bits & 8-14 bits & 15-23 bits & 24-31 bits \\
        \hline
        \hline
        192 & 168 & 000000 \textbf{01} & 00000000 \\
        \hline
        192 & 168 & 000000 \textbf{10} & 00000000 \\
    \end{tabular}
\end{center}

No difieren únicamente en el último bit, por lo que no cumplen con ser contiguas, por lo que no se puede realizar agregación de prefijos


\subsection{Caso Desfavorable por no ser contiguas - Next Hop}

\begin{center}
    \begin{tabular}{c|c}
        Máscara & Puerto de salida \\
        \hline
        \hline
         192.168.0.0/24 &  \textbf{0}\\
         \hline
         192.168.1.0/24 &  \textbf{1}
    \end{tabular}
\end{center}

Si bien son contiguas, al no compartir el next hop, no se puede realizar agregación de prefijos


\subsection{Ejercicio de parcial}

Simplificar la siguiente tabla

\begin{center}
    \begin{tabular}{c|c}
        Máscara & Puerto de salida \\
        \hline
        \hline
        157.128.2.0/23 &  0\\
        \hline
        168.123.0.0/24 &  1 \\
        \hline
        168.123.1.0/24 &  1 \\
        \hline
        168.12.128.0/19 &  2 \\
        \hline
        168.12.160.0/19 &  2 \\
    \end{tabular}
\end{center}


Únicamente se podrá hacer agregación en aquellas que tengan igual puerto de salida, serán las que se analizarán.
Se analizan las del puerto de salida 1

\begin{center}
    
    \begin{tabular}{c|c|c|c}

        0-7 bits & 8-14 bits & 15-23 bits & 24-31 bits \\
        \hline
        \hline
        168 & 123 & 0000000 \textbf{0} & 00000000 \\
        \hline
        168 & 123 & 0000000 \textbf{1} & 00000000 \\
    \end{tabular}
\end{center}


Difieren en el último bit, el prefijo es de igual longitud y el mismo puerto de salida. Realizo agregación de prefijos.


\begin{center}
    \begin{tabular}{c|c}
        Máscara & Puerto de salida \\
        \hline
        \hline
        168.123.0.0/23 &  1 \\
    \end{tabular}
\end{center}

Se analizan las del puerto de salida 2

\begin{center}
    \begin{tabular}{c|c|c|c}
        0-7 bits & 8-14 bits & 15-23 bits & 24-31 bits \\
        \hline
        \hline
        168 & 12 & 10\textbf{0} 00001 & 00000000 \\
        \hline
        168 & 12 & 10\textbf{1} 00000 & 00000000 \\
    \end{tabular}
\end{center}

Difieren en el último bit, el prefijo es de igual longitud y el mismo puerto de salida. Realizo agregación de prefijos 

\begin{center}
    \begin{tabular}{c|c}
        Máscara & Puerto de salida \\
        \hline
        \hline
        168.12.128.0/18 &  2 \\
    \end{tabular}
\end{center}

Tabla final simplificada

\begin{center}
    \begin{tabular}{c|c}
        Máscara & Puerto de salida \\
        \hline
        \hline
        157.128.2.0/23 &  0\\
        \hline
        168.123.0.0/23 &  1 \\
        \hline
        168.12.128.0/18 &  2 \\
    \end{tabular}
\end{center}



\section{Control de flujo y congestion}

Cada extremo de la transmisión TCP tiene su propio buffer, alli almacena datos TCP para pasarlos a la capa de aplicación. Si se reciben más datos de los que la capa de aplicación es capaz de consumir, ocurre un \textit{buffer overflow}. Para evitar esto, cada extremo comunica la cantidad de datos que puede recibir. A esto se lo llama \textbf{rwnd} o \textit{Receiver Window}. Va en el campo \textit{Window} del header de TCP.
Cuando se recibe un cambio en \textbf{rwnd}, el emisor debe modificar la tasa de envío para no provocar un \textit{buffer overflow} ni subutilizar el buffer. 
Si se recibe $\textbf{rwnd} = 0 $, el emisor debe dejar de enviar datos hasta recibir un nuevo valor de \textbf{rwnd}. Para recibir este nuevo valor, el emisor envía paquetes de 1 byte constantemente y el receptor responde con el tamaño de ventana. Cuando este tamaño ya no es cero, el emisor retoma el envio de datos.

La congestion es producto de múltiples flujos TCP en simultáneo sobre la misma red. Cunado se llena un buffer, se empiezan a descartar los segmentos. En estos casos se dice que la red está congestionada.

\textbf{cwnd} es la máxima cantidad de bytes que puede haber en vuelo.
$$ \mathrm{LastByteSent}-\mathrm{LastByteACKed} < \mathrm{min}(\mathrm{cwnd},\mathrm{rwnd}) $$


\subsection{Etapas en el control de congestion}

\begin{itemize}
    \item Slow Start
    \item Congestion avoidance
    \item Fast Retransmit
    \item Fast Recovery
\end{itemize}

\subsubsection{Slow Start}

$$\mathrm{cwnd}_{n+1} = \mathrm{cwnd_n} + \mathrm{MSS} \cdot \#\mathrm{ACK} $$

con \textbf{cwnd} medido en bytes


$$\mathrm{cwnd}_{n+1} = \mathrm{cwnd}_n + \#ACK $$

con \textbf{cwnd} medido en MSSs, es decir segmentos de tamaño máximo. Crece de manera exponencial. \\

\textbf{Ejemplo}



$$ \mathrm{cwnd}_0 = 1 $$

entonces envío 1 segmento, recibo 1 ACK. Luego 

$$ \mathrm{cwnd}_1 = \mathrm{cwnd}_0 + 1 = 1 + 1 = 2 $$

Envío entonces 2 segmentos, por los cuales recibo 2 ACKs

$$ \mathrm{cwnd}_2 = \mathrm{cwnd}_1 + \#ACK = 2 + 2 = 4 $$

Para frenar este crecimiento exponencial se cambia de etapa

\subsubsection{Congestion avoidance}

En un momento se da por terminada la etapa de slow start para pasar a la proximo, llamada congestion Avoidance. Esto viene dado por el valor \textbf{sstresh} o \textit{slow start threshold size}.

$$ \mathrm{cwnd}_{n+1} = \mathrm{cwnd}_n + \frac{\#ACK}{\mathrm{cwnd}_n} $$

Aumenta en 1 al llegar los ACKs de la ráfaga, cwnd \textbf{tiene que ser entero, la unidad es el MSS}. Llegado el caso, se redondea para abajo. \\

\textbf{Ejemplo}

$$\mathrm{cwnd}_n = 2$$

Entonces se envían 2 segmentos. Llega el primer ACK

$$ \mathrm{cwnd}_{n+1} = \mathrm{cwnd}_n +  \frac{\#ACK}{\mathrm{cwnd}_n} $$

$$ \mathrm{cwnd}_{n+1} = 2 +  \frac{1}{2} = 2.5 $$

$$ \mathrm{cwnd}_{n+1} = 2 $$

Llega el segundo ACK

$$ \mathrm{cwnd}_{n+2} = \mathrm{cwnd}_{n+1} +  \frac{\#ACK}{\mathrm{cwnd}_{n+1}} $$

$$ \mathrm{cwnd}_{n+2} = 2 +  \frac{2}{2} = 3 $$


\subsubsection{Pérdida de paquetes}

Pérdida por timeout (\textbf{RTO})

$$ \mathrm{ssthresh} = \frac{\mathrm{cwnd}_n}{2} $$

$$ \mathrm{cwnd}_{n+1} = 1  $$

1 es llamado LW o \textit{Loss Window}

\subsection{Ejercicio de parcial}


\input{ejercicioParcialTcp}

\subsection{Pérdida de un solo paquete}

Suponemos se está usando el algoritmo de control de congestion de Tahoe. 
Recibib ACK duplicados indica que llegan algunos paquetes de la rafaga. Ocurre cuando se reciben 4 ACKs para el mismo segmento (el primer ACK es válido, luego llegan 3 ACKs duplicados). Dependiendo del algoritmo implementado se vuelve a slow start o se realiza un fast recovery

\subsubsection{Tahoe}

Tahoe se comporto frente a los ACKs duplicados de igual manera que lo hace frente a un RTO. Es decir, realiza un \textbf{Fast Retransmit} y luego un \textbf{Slow start} \\

\textbf{Ejemplo}\\

Veamos que ocurre cuando se pierde un paquete de una ráfaga con el algoritmo de Tahoe. El inicio de la comunicación es identico al caso anterior

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/resolucion2.png}
\end{figure}

En primer lugar el three Way Handshake, y los envios de paquetes van creciendo exponencialmente ya que nos encontramos en slow start. Luego de recibidos los ACK para los paquetes 3,4,5 y 6 el valor de la ventana es $\mathrm{cwnd}_n = 8$ y $\mathrm{ssthresh}  = 32$

En la siguiente ráfaga el paquete 8 no llega a destino, es decir llegan 7 paquetes al servidor. Por lo que este contesta con 7 ACK pero asociados al último paquete previo al que no llegó, es decir el paquete 7.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/paqEnRafaga.png}
\end{figure}


Al realizar esto el servidor, lo que está haciendo es un NACK implícito. Se ingresa entonces en \textbf{Fast Retransmit}, donde se envía el paquete extraviado y se recibe un ACK correspondiente al último paquete que se recibió correctamente de la ráfaga previa (el 14).


\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/fastRetransmit.png}
\end{figure}

Posterior a esto se vuelve a Slow Start, y Tahoe se comportaba de igual manera que en un RTO, por lo que $\mathrm{cwnd}_n = 1$ y $\mathrm{ssthresh} = \frac{\mathrm{cwnd}_{n-1}}{2} = \frac{8}{2} = 4 $. Entonces se envía un paquete y se recibe el ACK correspondiente. Luego se envían 2 y se reciben sus ACKs, etc


\subsubsection{Reno}

El algoritmo de Reno actúa distinto a Tahoe. Cuando se reciben 4 ACKs iguales, se retransmite el siguiente segmento. Además luego los valores son $ \mathrm{cwnd}_{n+1} = \frac{\mathrm{cwnd}_{n}}{2} $ y $ \mathrm{ssthresh} = \frac{\mathrm{cwnd}_{n}}{2} $. Luego de esto, se continúa en congestion Avoidance. Esto se llama \textbf{Fast Recovery} \\

\textbf{Ejemplo} \\

Identico al anterior hasta perder el 8vo paquete de la ráfaga. Se hace un fast retransmit del paquete perdido y se actualizan los valores de ventana y threshold. $\mathrm{cwnd}_n = 8 $ y $\mathrm{ssthresh} = 32$.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/fastRetransmit.png}
\end{figure}

Luego de reenviar el paquete perdido en fast retransmit,  $\mathrm{cwnd}_{n+1} = \frac{\mathrm{cwnd}_{n}}{2} = \frac{8}{2} = 4 $ y $\mathrm{ssthresh} = 4 $. A continuación se entra en congestion avoidance.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/postCongA.png}
\end{figure}

\subsubsection{Cheatsheet}

\textbf{En Slow Start}

$$ \mathrm{cwnd}_{n+1} = \mathrm{cwnd}_{n} + \#\mathrm{ACK} $$

\textbf{Ocurre RTO}

$$ \mathrm{ssthresh} = \frac{\mathrm{cwnd}_n}{2} $$

$$ \mathrm{cwnd}_{n+1} = 1  $$

\textbf{Congestion Avoidance, $\mathrm{cwnd} \geq \mathrm{ssthresh} $}

$$ \mathrm{cwnd}_{n+1} = \mathrm{cwnd}_n + \frac{\#\mathrm{ACK}}{\mathrm{cwnd}_n} $$


\subsection{Ejercicios de Parcial}

\subsubsection{Ejercicio 1}

Un usuario descarga un recurso de 30960 bytes de un servidor por medio de un HTTP GET. Se sabe que el sistema operativo del usuario opera con TCP Tahoe y cuya IW=4MSS. El sistema utiliza un ssthresh=11520 bytes. Considerando: 1MSS = 1440 bytes
La conexión sufrirá la pérdida del séptimo segmento de datos transmitido \\

Se que $ 1 \; \mathrm{MSS} = 1440 \; \mathrm{bytes} $ entonces se pasa todo a MSS. Para el recurso de $ 30960 \; \mathrm{bytes} $, $ \frac{30960 \; \mathrm{bytes} }{1440 \; \mathrm{bytes}} = 21.5 \; \mathrm{MSS}$. Como es el tamaño del archivo, para descargarlo por completo redondeo hacia arriba, entonces $ \mathrm{Recurso} = 22 \; \mathrm{MSS} $. Los mismo para $\mathrm{ssthresh}= 11520 \;\mathrm{bytes}$, entonces $\mathrm{ssthresh}= 8$. 
Como $\mathrm{IW} = 4 \; \mathrm{MSS}$ se comienza con $ \mathrm{cwnd}_n = 4$.



Primero el three way handshake para establecer la conexion TCP. Luego enviamos los primeros 4 paquetes y recibimos los 4 ACKs.


\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/resEj11.png}
\end{figure}

$ \mathrm{cwnd}_{n+1} = \mathrm{cwnd}_{n} + \#\mathrm{ACK} = 4 + 4 = 8 $. Se procede a enviar los siguientes 8 segmentos. Pero por consigna el 7mo no llega a destino. Por lo que se hace fast retransmit del segmento que no llega.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/resEj12.png}
\end{figure}

Como el algoritmo es Tahoe, posterior al Fast Retransmit, se vuelve a slow Start se tendrá $ \mathrm{cwnd}_{n+2} = 1 $ y   $\mathrm{ssthresh}= 4 $.

Se envía entonces un segmento, se recibe su ACK correspondiente. Por estar en Slow Start ahora  $ \mathrm{cwnd}_{n+3} = 2 $. Se envian 2 paquetes y se reciben los 2 ACKs. Ahora $ \mathrm{cwnd}_{n+4} = 4 $. Recordando que   $\mathrm{ssthresh}= 4 $, se envían 4 paquetes y se reciben los 4 ACK, pero ahora se actualiza distinto la ventana por haber entrado en Congestion Avoidance. $ \mathrm{cwnd}_{n+5} = \mathrm{cwnd}_{n+4} + \frac{\#\mathrm{ACK}}{\mathrm{cwnd}_{n+4}} = 4 + \frac{4}{4} = 5 $. 

Sin embargo, con enviar 3 paquetes más se completa la descarga del archivo. Se finaliza terminando la conexión.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{imagenes/resEj13.png}
\end{figure}

\subsubsection{Ejercicio 2}
Por medio de una conexión TCP se transfiere desde un host A a un host B un archivo de 27326 B. De acuerdo con las tecnologías de enlace que utiliza el host A, MSS=1500B. Además, sabemos que su sistema operativo opera con TCP Tahoe, con una IW=1MSS. El sistema utiliza ssthresh=4MSS. Sabemos que la conexión sufrirá la pérdida del séptimo segmento de datos transmitido.

\subsubsection{Ejercicio 3}

Considere el efecto de usar Slow Start en una conexión TCP recién establecida (IW = 2 * SMSS, SSTHRESH = 64KB), que tiene un RTT de 10 mseg y sin congestión ni errores presentes en la red. La RWND es de 24KB y el SMSS es de 2KB. ¿Cuánto tiempo transcurre antes de que pueda ser enviada la primera ventana de recepción llena? (Asumir que el Ttx de una ventana es una componente despreciable del Delay total de la conexión)


\begin{center}
    \begin{tabular}{c|c|c|c}
        RTT & CWND & RWND & FlightSize \\
        \hline
        \hline
        1 & & & \\
         \hline
        2 & & & \\
         \hline
        3 & & & \\
         \hline
        4 & & & \\
         \hline
        5 & & & \\
         \hline
        6 & & & \\
         \hline
        7 & & & \\
         \hline
        8 & & & \\
         \hline
        9 & & & \\
         \hline
        10 & & & \\
    \end{tabular}
\end{center}


\subsubsection{Ejercicio 4 - Reno}

Por medio de una conexión TCP se transfiere desde un host A a un host B un archivo de 41326 B. De acuerdo con las tecnologías de enlace que utiliza el host A, MSS=2000B. Además, sabemos que su sistema operativo opera con TCP Reno, con una IW=2MSS. El sistema utiliza ssthresh=8MSS. Sabemos que la conexión sufrirá la pérdida del décimo segmento de datos transmitido.

\section{Fragmentacion}\label{sec:fragmentacion}

\input{Fragmentacion}

\section{Subnetting}\label{sec:subnetting}

\section{Teoria}\label{sec:teoria}

\subsection{Capa de Aplicación}\label{sec:capaaplicacion}

Los protocolos de la capa de aplicación se implementan en los hosts


\subsection{Protocolo\label{sec:protocolo}}


\subsubsection{ ¿Cuál es la función de un protocolo de capa de aplicación?}

La función de un protocolo de la capa de aplicación es la de ...

\subsubsection{¿Qué define un protocolo?} 
Conjunto definido de reglas y procedimientos que determinan cómo se transmiten los datos en las redes de computadoras. Un protocolo define:

\begin{itemize}
    \item Mensajes de petición y respuesta
    \item Sintaxis de los mensajes
    \item Campos - función, tamaño y delimitadores
    \item Procedimiento de envío de mensajes y sus respuestas
\end{itemize}

\end{document}
